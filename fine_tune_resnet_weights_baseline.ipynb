{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T09:22:05.686092Z",
     "start_time": "2021-02-24T09:22:05.660308Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "import json\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as trn\n",
    "from torchnet import meter\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from captioning.utils.resnet_utils import myResnet\n",
    "import captioning.utils.resnet as resnet\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.resnet\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import  Draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T09:28:00.555441Z",
     "start_time": "2021-02-05T09:27:57.250101Z"
    }
   },
   "outputs": [],
   "source": [
    "from chembl_webresource_client.new_client import new_client\n",
    "molecule = new_client.molecule\n",
    "approved_drugs0 = molecule.filter(max_phase=0)\n",
    "approved_drugs1 = molecule.filter(max_phase=1)\n",
    "approved_drugs2 = molecule.filter(max_phase=2)\n",
    "approved_drugs3 = molecule.filter(max_phase=3)\n",
    "approved_drugs4 = molecule.filter(max_phase=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T09:28:00.993511Z",
     "start_time": "2021-02-05T09:28:00.557520Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smiles0 = []\n",
    "smiles1 = []\n",
    "smiles2 = []\n",
    "smiles3 = []\n",
    "smiles4 = []\n",
    "for i,mol in enumerate(tqdm(approved_drugs0)):\n",
    "    try:\n",
    "        smiles0.append(mol['molecule_structures']['canonical_smiles'])\n",
    "    except:\n",
    "        continue\n",
    "#     if i == 3000:\n",
    "#         break\n",
    "for i,mol in enumerate(tqdm(approved_drugs1)):\n",
    "    try:\n",
    "        smiles1.append(mol['molecule_structures']['canonical_smiles'])\n",
    "    except:\n",
    "        continue\n",
    "for i,mol in enumerate(tqdm(approved_drugs2)):\n",
    "    try:\n",
    "        smiles2.append(mol['molecule_structures']['canonical_smiles'])\n",
    "    except:\n",
    "        continue\n",
    "for i,mol in enumerate(tqdm(approved_drugs3)):\n",
    "    try:\n",
    "        smiles3.append(mol['molecule_structures']['canonical_smiles'])\n",
    "    except:\n",
    "        continue\n",
    "for i,mol in enumerate(tqdm(approved_drugs4)):\n",
    "    try:\n",
    "        smiles4.append(mol['molecule_structures']['canonical_smiles'])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T08:37:22.308228Z",
     "start_time": "2021-02-05T08:35:38.543717Z"
    }
   },
   "outputs": [],
   "source": [
    "for i,smile in enumerate(tqdm(smiles0)):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    Draw.MolToFile(mol,'mols/0/'+str(i)+'.png')\n",
    "for i,smile in enumerate(tqdm(smiles1)):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    Draw.MolToFile(mol,'mols/1/'+str(i)+'.png')\n",
    "for i,smile in enumerate(tqdm(smiles2)):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    Draw.MolToFile(mol,'mols/2/'+str(i)+'.png')\n",
    "for i,smile in enumerate(tqdm(smiles3)):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    Draw.MolToFile(mol,'mols/3/'+str(i)+'.png')\n",
    "for i,smile in enumerate(tqdm(smiles4)):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    Draw.MolToFile(mol,'mols/4/'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T10:02:45.814599Z",
     "start_time": "2021-02-05T10:02:45.617858Z"
    }
   },
   "outputs": [],
   "source": [
    "li = []\n",
    "di = {}\n",
    "for image in tqdm(os.listdir('mols/0')):\n",
    "    di['image'] = 'mols/0/'+str(image)\n",
    "    di['label'] = '0'\n",
    "    li.append(copy.deepcopy(di))\n",
    "for image in tqdm(os.listdir('mols/1')):\n",
    "    di['image'] = 'mols/1/'+image\n",
    "    di['label'] = '1'\n",
    "    li.append(copy.deepcopy(di))\n",
    "\n",
    "for image in tqdm(os.listdir('mols/2')):\n",
    "    di['image'] = 'mols/2/'+image\n",
    "    di['label'] = '2'\n",
    "    li.append(copy.deepcopy(di))\n",
    "\n",
    "\n",
    "for image in tqdm(os.listdir('mols/3')):\n",
    "    di['image'] = 'mols/3/'+image\n",
    "    di['label'] = '3'\n",
    "    li.append(copy.deepcopy(di))\n",
    "\n",
    "\n",
    "for image in tqdm(os.listdir('mols/4')):\n",
    "    di['image'] = 'mols/4/'+image\n",
    "    di['label'] = '4'\n",
    "    li.append(copy.deepcopy(di))\n",
    "\n",
    "with open('mols/mols.json','w') as f:\n",
    "    json.dump(li,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T11:00:47.877992Z",
     "start_time": "2021-02-24T11:00:47.869416Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class molsDataset(Dataset):\n",
    "    def __init__(self, results, transform=None):\n",
    "        \"\"\"\n",
    "        :param data_dir: str, 数据集所在路径\n",
    "        :param transform: torch.transform，数据预处理\n",
    "        \"\"\"\n",
    "#         self.label_name = {'0':0,'1':1,'2':2,'3':3,'4':4}\n",
    "        self.label_name = {'0':0,'4':1}\n",
    "        self.data_info = self.get_img_info(results)  # data_info存储所有图片路径和标签，在DataLoader中通过index读取样本\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):  # 函数功能是根据index索引去返回图片img以及标签label\n",
    "        path_img, label = self.data_info[index]\n",
    "        img = Image.open(path_img).convert('RGB')     # 0~255\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)   # 在这里做transform，转为tensor等等\n",
    "\n",
    "\n",
    "        return img, label\n",
    "    def __len__(self):   # 函数功能是用来查看数据的长度，也就是样本的数量\n",
    "        return len(self.data_info)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_img_info(results):   # 函数功能是用来获取数据的路径以及标签\n",
    "        data_info = list()\n",
    "        for result in results:\n",
    "            # 遍历类别\n",
    "                path_img = result['image']\n",
    "                label = result['label']\n",
    "                data_info.append((path_img, int(label)))\n",
    "        return data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T11:00:56.591502Z",
     "start_time": "2021-02-24T11:00:56.542467Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = trn.Compose([\n",
    "                trn.ToTensor(),\n",
    "                trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "with open('mols/mols.json','r') as f:\n",
    "    datas = json.load(f)\n",
    "train_data = molsDataset(datas,transform=preprocess) \n",
    "valid_data = molsDataset(datas,transform=preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T11:01:24.649781Z",
     "start_time": "2021-02-24T11:01:24.643086Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True) # shuffle=True，每一个epoch中样本都是乱序的\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T10:52:55.939580Z",
     "start_time": "2021-02-24T10:52:55.931867Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(torchvision.models.resnet.ResNet):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        super(ResNet, self).__init__(block, layers, num_classes)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True) # change\n",
    "        for i in range(2, 5):\n",
    "            getattr(self, 'layer%d'%i)[0].conv1.stride = (2,2)\n",
    "            getattr(self, 'layer%d'%i)[0].conv2.stride = (1,1)\n",
    "\n",
    "def resnet101(pretrained=False):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T10:54:57.329274Z",
     "start_time": "2021-02-24T10:54:57.321034Z"
    }
   },
   "outputs": [],
   "source": [
    "class myResnet(nn.Module):\n",
    "    def __init__(self, resnet,num_classes):\n",
    "        super(myResnet, self).__init__()\n",
    "        self.resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(in_features=2048, out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T10:58:07.378497Z",
     "start_time": "2021-02-24T10:58:02.309871Z"
    }
   },
   "outputs": [],
   "source": [
    "net = getattr(resnet, 'resnet101')()\n",
    "net.load_state_dict(torch.load(os.path.join('./data/imagenet_weights','resnet101'+'.pth')))\n",
    "my_resnet = myResnet(net,num_classes=2)\n",
    "my_resnet.cuda()\n",
    "device_ids = [0, 1,2,3]\n",
    "net = torch.nn.DataParallel(my_resnet, device_ids=device_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T10:06:42.115173Z",
     "start_time": "2021-02-05T10:06:42.105330Z"
    }
   },
   "outputs": [],
   "source": [
    "class FocalSmoothedLoss(_WeightedLoss):\n",
    "    def __init__(self, gamma=2, weight=None, reduction='mean'):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logpt = F.log_softmax(inputs, dim=1)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = (1-pt)**self.gamma * logpt\n",
    "#         lsm = F.nll_loss(logpt, targets, self.weight)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "#         loss = -(targets * lsm).sum(-1)\n",
    "        loss = F.nll_loss(logpt, targets, self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T11:01:41.064431Z",
     "start_time": "2021-02-24T11:01:41.054931Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = FocalSmoothedLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-5, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T11:01:46.263058Z",
     "start_time": "2021-02-24T11:01:46.230205Z"
    }
   },
   "outputs": [],
   "source": [
    "def val():\n",
    "    net.eval()\n",
    "    total_val = 0\n",
    "    correct_val = 0\n",
    "    loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(valid_loader)\n",
    "        for data in t:\n",
    "            inputs,labels = data[0].cuda(),data[1].cuda()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            print(predicted)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).cpu().squeeze().sum().numpy()\n",
    "            loss_val += loss.item()\n",
    "            t.set_description('acc: %s  Loss: %s' %(str(correct_val/total_val),loss.item()))\n",
    "        print('acc: %s  Loss: %s' %(str(correct_val/total_val),loss_val/len(t)))\n",
    "    return correct_val/total_val,loss_val/len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-24T11:02:59.218441Z",
     "start_time": "2021-02-24T11:02:02.697107Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "for i in range(50):\n",
    "    t = tqdm(train_loader)\n",
    "    for data in t:\n",
    "        inputs,labels = data[0].cuda(),data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t.set_description('epoch: %s  Loss: %s' %(str(i),loss.item()))\n",
    "    scheduler.step()\n",
    "    print('epoch: %s  Loss: %s' %(str(i),loss.item()))\n",
    "    acc,mean_loss = val()\n",
    "    state = {'net':net.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch':str(i)}\n",
    "    torch.save(state, \"log/mean_loss:\"+str(mean_loss)+'acc:'+str(acc)+'epoch:'+str(i)+'.pth') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:yuxiao] *",
   "language": "python",
   "name": "conda-env-yuxiao-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
